{
 "cells": [
  {
   "cell_type": "code",
   "id": "78b16fec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:30:04.063638Z",
     "start_time": "2025-01-23T21:29:52.906355Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy import VideoFileClip\n",
    "import math\n",
    "\n",
    "# Parameters\n",
    "min_contour_width = 40  # Minimum width of a detected contour\n",
    "min_contour_height = 40  # Minimum height of a detected contour\n",
    "line_orientation = \"vertical\"  # \"horizontal\" or \"vertical\"\n",
    "line_position = 550  # Position of the counting line\n",
    "offset = 10  # Offset for line crossing detection\n",
    "tracking_duration_threshold = 1 # Frames required for continuous tracking\n",
    "vehicles = 0  # Counter for vehicles\n",
    "frame_id = 0\n",
    "\n",
    "# Noise metrics\n",
    "db_levels = []  # List to store dB levels for analysis\n",
    "\n",
    "# Tracking\n",
    "active_tracks = {}  # Dictionary to store tracked object states\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(\"Timeline1.mp4\")  # Replace with your video file path\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_duration = 1 / fps  # Duration of each frame in seconds\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "video_duration = total_frames / fps  # Total video duration in seconds\n",
    "\n",
    "# Vehicles per hour initialization\n",
    "vehicles_per_hour = 0\n",
    "\n",
    "# Extract audio from the video\n",
    "audio_clip = VideoFileClip(\"Timeline1.mp4\").audio\n",
    "audio_fps = audio_clip.fps\n",
    "audio_array = audio_clip.to_soundarray(fps=audio_fps)\n",
    "\n",
    "# Function to compute dB levels\n",
    "def calculate_db(audio_segment):\n",
    "    rms = np.sqrt(np.mean(np.square(audio_segment)))\n",
    "    db = 20 * math.log10(rms) if rms > 0 else -float(\"inf\")\n",
    "    return max(db, -100) *-1 # Clip to -100 dB as minimum for visualization\n",
    "\n",
    "# Get initial frames\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Error: Could not read frames from video.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "def get_centroid(x, y, w, h):\n",
    "    \"\"\"Calculate the centroid of a bounding box.\"\"\"\n",
    "    return (int(x + w / 2), int(y + h / 2))\n",
    "\n",
    "# Processing loop\n",
    "while ret:\n",
    "    # Calculate frame difference\n",
    "    d = cv2.absdiff(frame1, frame2)\n",
    "    grey = cv2.cvtColor(d, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (5, 5), 0)\n",
    "\n",
    "    # Thresholding and morphological operations\n",
    "    _, th = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(th, np.ones((3, 3)), iterations=2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Filter contours by size\n",
    "        if w >= min_contour_width and h >= min_contour_height:\n",
    "            centroid = get_centroid(x, y, w, h)\n",
    "            active_tracks[frame_id] = {\n",
    "                \"centroid\": centroid,\n",
    "                \"frames\": active_tracks.get(frame_id, {}).get(\"frames\", 0) + 1,\n",
    "            }\n",
    "            cv2.rectangle(frame1, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.circle(frame1, centroid, 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Check and count objects meeting the tracking threshold\n",
    "    keys_to_remove = []\n",
    "    for key, value in active_tracks.items():\n",
    "        cx, cy = value[\"centroid\"]\n",
    "        if value[\"frames\"] >= tracking_duration_threshold:\n",
    "            if line_orientation == \"horizontal\":\n",
    "                if (line_position - offset) < cy < (line_position + offset):\n",
    "                    vehicles += 1\n",
    "                    keys_to_remove.append(key)\n",
    "            elif line_orientation == \"vertical\":\n",
    "                if (line_position - offset) < cx < (line_position + offset):\n",
    "                    vehicles += 1\n",
    "                    keys_to_remove.append(key)\n",
    "\n",
    "    for key in keys_to_remove:\n",
    "        active_tracks.pop(key, None)\n",
    "\n",
    "    # Extract audio segment corresponding to the current frame\n",
    "    audio_start_index = int((frame_id / fps) * audio_fps)\n",
    "    audio_end_index = int(((frame_id + 1) / fps) * audio_fps)\n",
    "    audio_segment = audio_array[audio_start_index:audio_end_index]\n",
    "\n",
    "    # Calculate and record dB levels\n",
    "    db_level = calculate_db(audio_segment)\n",
    "    db_levels.append(db_level)\n",
    "\n",
    "    # Draw the counting line\n",
    "    if line_orientation == \"horizontal\":\n",
    "        cv2.line(frame1, (0, line_position), (frame1.shape[1], line_position), (0, 255, 0), 2)\n",
    "    elif line_orientation == \"vertical\":\n",
    "        cv2.line(frame1, (line_position, 0), (line_position, frame1.shape[0]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display vehicle count and audio level\n",
    "    cv2.putText(frame1, f\"Total Vehicles: {vehicles}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(frame1, f\"Audio Level (dB): {db_level:.2f}\", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Vehicle Detection and Audio Analysis\", frame1)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) == 27:  # ESC key\n",
    "        break\n",
    "\n",
    "    # Update frames\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "    frame_id += 1\n",
    "\n",
    "# Calculate statistics\n",
    "max_db = max(db_levels)\n",
    "min_db = min(db_levels)\n",
    "average_db = sum(db_levels) / len(db_levels)\n",
    "\n",
    "# Calculate vehicles per hour\n",
    "total_hours = video_duration / 3600  # Convert video duration to hours\n",
    "vehicles_per_hour = vehicles / total_hours\n",
    "\n",
    "# Report summary\n",
    "print(\"\\n==== Video Analysis Report ====\")\n",
    "print(f\"Total Vehicles Detected: {vehicles}\")\n",
    "print(f\"Vehicles Per Hour: {vehicles_per_hour:.2f}\")\n",
    "print(f\"Maximum Noise Level (dB): {max_db:.2f}\")\n",
    "print(f\"Minimum Noise Level (dB): {min_db:.2f}\")\n",
    "print(f\"Average Noise Level (dB): {average_db:.2f}\")\n",
    "print(\"================================\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 126\u001B[0m\n\u001B[0;32m    123\u001B[0m cv2\u001B[38;5;241m.\u001B[39mputText(frame1, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAudio Level (dB): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdb_level\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m100\u001B[39m), cv2\u001B[38;5;241m.\u001B[39mFONT_HERSHEY_SIMPLEX, \u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m255\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    125\u001B[0m \u001B[38;5;66;03m# Display the frame\u001B[39;00m\n\u001B[1;32m--> 126\u001B[0m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mVehicle Detection and Audio Analysis\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cv2\u001B[38;5;241m.\u001B[39mwaitKey(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m27\u001B[39m:  \u001B[38;5;66;03m# ESC key\u001B[39;00m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
